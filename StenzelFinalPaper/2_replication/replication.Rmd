---
title: "On Using the Metropolis-Hastings Algorithm for Data Imputation"
author: "Tobias Stenzel"
date: "`r format(Sys.time(), '%B %d, %Y')`"
header-includes:
   - \usepackage{tikz, float, caption, amsthm, algorithm, algpseudocode}
   - \floatplacement{figure}{H}
   #- \newtheorem{definition}{Definition}
   - \interfootnotelinepenalty=10000 # no multi-page footnotes
output:
  bookdown::pdf_document2:
    template: template.tex
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
    keep_tex: yes
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
bibliography: bibliography.bib
csl-hanging-indent: yes
fontsize: 12pt 
linestretch: 2.0 # adjust for line spacing 
geometry: left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm
classoption:
- a4paper
- oneside
lang: en-EN
numbersections: yes
csquotes: yes
type: Final Paper for Course
course: Advanced Quantitative Methods in Political Science
subtitle: ''
address: ''
email: tobias.stenzel@students.uni-mannheim.de
phone: ''
examiner: Prof. Thomas Gschwend, Ph.D.
chair: ''
mp: 0.55
ID: ''
# STRONGLY BIASED wordcount: '*Wordcount excluding References: `r unima::count_words(knitr::current_input())`*' 
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/american-political-science-association.csl
editor_options:
  markdown:
    wrap: sentence
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      include=FALSE,
                      fig.path = "figs/",
                      out.width="\\textwidth"
                      )

p_needed <- c(# all packages you need to install here
  "knitr",
  "bookdown", # referencing figures and tables by label
  "remotes",
  "ggplot2",
  "stargazer",
  "dplyr", # to compute leads values
  "tidyr", # for dropping nans
  "GGally", # correlation matrix style plots
  "gridExtra", # grid for multiple plots
  "cowplot",
  "MASS", # glm
  "janitor", # fd plot over range
  #"countreg", # rootogram
  "ggeasy", # remove axes
  "latex2exp", # latex legend labels
  "ggridges",
  #christopher claassen's additional requirements
  "arm",
  "loo",
  "rstan",
  "RColorBrewer"
  )


# installs only the required packages 
lapply(p_needed[!(p_needed %in% rownames(installed.packages()))], install.packages)
lapply(p_needed, library, character.only = TRUE)

# separately install for the correct wordcount package 
if (!"unima" %in% rownames(installed.packages())){
  remotes::install_github("vktrsmnv/unima-template", upgrade = "never", dependencies = TRUE)
  }

# this allows you to add notes to figures with a simple chunk option
# you only need to add "notes="text" as a chunk option; 
# the notes will only appear in PDF output
hook_chunk = knit_hooks$get('chunk')
knit_hooks$set(chunk = function(x, options) {
  txt = hook_chunk(x, options)
  # add chunk option 'description' which adds \Description{...} to figures
  if (!is.null(options$notes)) {
    latex_include <- paste0("\\\\vspace\\{0.5cm\\} \\\\\\footnotesize\\{\\\\textit\\{Notes: \\}", options$notes, "\\} \\1")
    gsub('(\\\\end\\{figure\\})', latex_include, txt) 
  } else {
    return(txt)  # pass to default hook
  }
})
if (knitr::is_latex_output()) knitr::knit_hooks$set(plot = knitr::hook_plot_tex)

# This is an option for stargazer tables
# It automatically adapts the output to html or latex,
# depending on whether we want a html or pdf file
stargazer_opt <- ifelse(knitr::is_latex_output(), "latex", "html")

# This ensures that if the file is knitted to HTML,
# significance notes are depicted correctly 
if (stargazer_opt == "html"){
  fargs <- formals(stargazer)
  fargs$notes.append = FALSE
  fargs$notes = c("<em>&#42;p&lt;0.1;&#42;&#42;p&lt;0.05;&#42;&#42;&#42;p&lt;0.01</em>")
  formals(stargazer) <- fargs
}

# only relevant for ggplot2 plotting
# setting a global ggplot theme for the entire document to avoid 
# setting this individually for each plot 
theme_set(theme_classic() + # start with classic theme 
  theme(
    plot.background = element_blank(),# remove all background 
    plot.title.position = "plot", # move the plot title start slightly 
    legend.position = "bottom" # by default, put legend on the bottom
  ))

set.seed(2021)
```

```{r configs}
# stan options
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

# folders
WD = rstudioapi::getActiveDocumentContext()$path 
setwd(dirname(WD))
print( getwd() )

# read support for dem data. NOTE: We have RespN instead of RespPerc as in online material
sddem1 = read.csv("raw-data/supdem raw survey marginals.csv")
```

```{r data-processing}
# remove NAs
sddem1 = sddem1[!sddem1$Response==0, ]

# create year by country indicators
year0 = 1987
sddem1 = sddem1[sddem1$Year > year0,]
sddem1 = unite(sddem1, YearCountry, c(Year, Country), sep = "_", remove = FALSE)

# create item by country indicators
sddem1 = unite(sddem1, ItemCnt, c(Item, Country), sep = "_", remove = FALSE)

# create year by project indicators
sddem1 = unite(sddem1, YrProj, c(Year, Project), sep = "_", remove = FALSE)

# create year by project by country indicators
sddem1 = unite(sddem1, YrProjCnt, c(YrProj, Country), sep = "_", remove = FALSE)


# factorise
sddem1$Country = as.factor(as.character(sddem1$Country))
sddem1$Item = as.factor(as.character(sddem1$Item))
sddem1$ItemCnt = as.factor(as.character(sddem1$ItemCnt))
sddem1$Project = as.factor(as.character(sddem1$Project))
sddem1$YrProj = as.factor(as.character(sddem1$YrProj))
sddem1$YrProjCnt = as.factor(as.character(sddem1$YrProjCnt))
sddem1$Year = sddem1$Year-year0

# count data
dim(sddem1)[1]                   # 3765 national responses
length(unique(sddem1$Country))   # 150 countries
length(unique(sddem1$Project))   # 14 projects
length(unique(sddem1$Item))      # 52 items
length(unique(sddem1$ItemCnt))   # 1453 item-country
length(unique(sddem1$YrProjCnt)) # 1390 national surveys
length(unique(sddem1$Year))      # 27 unique years (out of 30)
sum(sddem1$Sample) / dim(sddem1)[1] * length(unique(sddem1$YrProjCnt))   # 1,804,450 respondents              
```

```{r drop-countries-with-only-1-year-of-survey-measures}
# drop countries with less than 2 years of data
cnt.obs.years = rowSums(table(sddem1$Country, sddem1$Year) > 0)
sort(cnt.obs.years)
sddem2 = sddem1[sddem1$Country %in% levels(sddem1$Country)[cnt.obs.years > 1], ]
length(unique(sddem2$Country))   # 137 countries with 2+ years of data


```




```{r prepare-for-stan}
# prepare data for stan
n.items = length(unique(sddem2$Item))
n.cntrys = length(unique(sddem2$Country))
n.yrs = 2017-year0
n.proj = length(unique(sddem2$Project))
n.resp = dim(sddem2)[1]
n.itm.cnt = length(unique(sddem2$ItemCnt))
n.cntry.yrs = n.cntrys * n.yrs
n.yr.proj.cnt = length(unique(sddem2$YrProjCnt))
cntrys = as.numeric(factor(sddem2$Country))
cnt.names = as.character(sort(unique(sddem2$Country)))
cnt.code = as.character(sddem2[match(cnt.names, sddem2$Country), "CAbb"])
cnt.code[83] = "MNE"
cnt.code[106] = "SRB"
items = as.numeric(factor(sddem2$Item))
yrs = sddem2$Year
projs = as.numeric(factor(sddem2$Project))
itm.cnts = as.numeric(factor(sddem2$ItemCnt))

# specify data for stan
dat.1 = list(N=n.resp, K=n.items, T=n.yrs, J=n.cntrys, jj=cntrys, tt=yrs, kk=items, 
             x=sddem2$Response, samp=sddem2$Sample)
dat.2 = list(N=n.resp, K=n.items, T=n.yrs, J=n.cntrys, P=n.itm.cnt, jj=cntrys, tt=yrs, 
             pp=itm.cnts, kk=items, x=sddem2$Response, samp=sddem2$Sample)
sapply(dat.2, summary)


```


```{r setparams-and-hyperparams}

# pars
pars.4 = c("mu_lambda","sigma_lambda","sigma_theta","phi","lambda","theta","x_pred","log_lik")
pars.5 = c("mu_lambda","sigma_lambda","sigma_delta","sigma_theta","phi","lambda","delta","theta",
            "x_pred","log_lik")
pars.6 = c("Sigma","Omega","sigma_delta","sigma_theta","phi","lambda","gamm","delta","theta",
           "x_pred","log_lik")

# iterations
n.iter = 500
n.warm = 250
n.chn = 4
n.thin = 1
```



```{r estimate-models}
# best model from PA article (model 5)
stan.mod.5 = stan(file='supdem.stan.mod5.stan', data=dat.2, pars=pars.5, 
                   iter=n.iter, warmup=n.warm, chains=n.chn, thin=n.thin, 
                   control=list(adapt_delta=0.99, stepsize=0.02, max_treedepth=11))

```


```{r traceplot}
#pdf("figure_S2B.pdf", width=10, height=4)
rstan::traceplot(stan.mod.5, ncol=5, nrow=2, alpha=0.8, size=0.3, 
          pars=c("mu_lambda","sigma_lambda","sigma_theta","sigma_delta","phi","lambda[15]",
                 "delta[107]","theta[21,66]","theta[16,49]","theta[16,101]"))

```


```{r rhat}
stan_rhat(stan.mod.5)


```


```{r extract-theta estimates}
#### Extract theta estimates

# impute thetas as suptrim

theta.out = rstan::extract(stan.mod.5, pars = c("theta"))[[1]]
theta.std = (theta.out - mean(as.vector(theta.out))) / sd(as.vector(theta.out)) # standardize
theta.out.t = apply( theta.std, 1, function(x) t(x) )
theta.out.df = data.frame(Country=rep(cnt.names, length.out=n.cntrys*30), 
                          ISO_code=rep(cnt.code, length.out=n.cntrys*30),
                          Year=rep(1988:2017, each=n.cntrys), theta.out.t)
theta.pe = theta.out.df[,1:3]
theta.dim = dim(theta.out.df)[2]
theta.pe$SupDem_trim = apply(theta.out.df[,4:theta.dim], 1, mean)

first.yr = data.frame(Country=levels(sddem2$Country),
                      First_yr = as.vector(by(sddem2, sddem2$Country, function(x) min(as.numeric(x$Year))+1987)))

theta.pe = merge(theta.pe, first.yr, by="Country", all.x=TRUE)
cnts = theta.pe[theta.pe$Year==2008, "Country"]
frst.yr = theta.pe[theta.pe$Year==2008, "First_yr"]
for(i in 1:length(cnts)) {
  theta.pe[theta.pe$Country==cnts[i] & theta.pe$Year<frst.yr[i], "SupDem_trim"] = NA
}

write.csv(theta.pe, "stan_est_sup_dem_m5.csv", row.names=FALSE)


```





