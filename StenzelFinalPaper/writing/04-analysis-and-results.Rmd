## Latent Opinion as Quantity of Interest

Our goal is to analyze the sensitivity of the MH algorithm towards changes in its hyperparameters. Since @Claassen2019estimating already tested different priors, we are particularly interested in the effect of different choices for the proposal distribution $g(y_i, y_{i-1})$ and the length of the burnin period. Although choosing
 parameters representing the main results in @Claassen2020mood and @Claassen2020support would be most illustrative in terms of substantial effects, this choice has the two following disadvantages. First, because these statistical parameters are estimated from simulated data, they are influenced by randomness from the data simulation that could not be distinguished from the estimation-inherent randomness. Second, the additional steps of simulating data and estimating statistical models would potentially double the computation time. Therefore, I choose the latent, dynamic, country-specific PSD $\theta$ as the Quantity of Interest.
 
The results for countries blabla by Classen2020 are shown in Figure blabla...



```{r generate-data}
#### Stan estimation

# time chunk execution
start_time <- Sys.time()

# parallelization
options(mc.cores = parallel::detectCores())
#aa llows you to automatically save a bare version of a compiled Stan program to the hard disk so that it does not need to be recompiled (unless you change it). You will need to run these commands each time you load the rstan library.
rstan_options(auto_write = TRUE)

# prepare data for stan
n.items = length(unique(df2$Item))
n.cntrys = length(unique(df2$Country))
n.yrs = 2017-year0
n.proj = length(unique(df2$Project))
n.resp = dim(df2)[1]
n.itm.cnt = length(unique(df2$ItemCnt))
n.cntry.yrs = n.cntrys * n.yrs
n.yr.proj.cnt = length(unique(df2$YrProjCnt))
cntrys = as.numeric(factor(df2$Country))
cnt.names = as.character(sort(unique(df2$Country)))
cnt.code = as.character(df2[match(cnt.names, df2$Country), "CAbb"])
cnt.code[83] = "MNE"
cnt.code[106] = "SRB"
items = as.numeric(factor(df2$Item))
yrs = df2$Year
projs = as.numeric(factor(df2$Project))
itm.cnts = as.numeric(factor(df2$ItemCnt))

# specify data for stan
dat.1 = list(N=n.resp, K=n.items, T=n.yrs, J=n.cntrys, jj=cntrys, tt=yrs, kk=items, 
             x=df2$Response, samp=df2$Sample)
dat.2 = list(N=n.resp, K=n.items, T=n.yrs, J=n.cntrys, P=n.itm.cnt, jj=cntrys, tt=yrs, 
             pp=itm.cnts, kk=items, x=df2$Response, samp=df2$Sample)
sapply(dat.2, summary)

# pars
pars.5 = c("mu_lambda","sigma_lambda","sigma_delta","sigma_theta","phi","lambda","delta","theta",
            "x_pred","log_lik")

# iterations
#n.iter = 500
n.chn = 4
n.thin = 1
times = c()
t = 1
#itergrid = seq(from=12, to=24, by=2)
iter1 =  seq(from=10, to=460, by=30)
iter2 =  seq(from=500, to=1000, by=100)
itergrid = c(iter1, iter2)
```

```{r long-loop, eval=FALSE}
for(n.iter in itergrid){
  n.warm = n.iter/2


  # best model from PA article (model 5)
  stan.mod.5 = stan(file='model5.stan', data=dat.2, pars=pars.5, 
                     iter=n.iter, warmup=n.warm, chains=n.chn, thin=n.thin, 
                     control=list(adapt_delta=0.99, stepsize=0.02, max_treedepth=11), seed=n.iter)
  
  
  #### Extract theta estimates
  
  theta.out = rstan::extract(stan.mod.5, pars = c("theta"))[[1]]
  theta.std = (theta.out - mean(as.vector(theta.out))) / sd(as.vector(theta.out)) # standardize
  theta.out.t = apply( theta.std, 1, function(x) t(x) )
  theta.out.df = data.frame(Country=rep(cnt.names, length.out=n.cntrys*30), 
                            ISO_code=rep(cnt.code, length.out=n.cntrys*30),
                            Year=rep(1988:2017, each=n.cntrys), theta.out.t)
  theta.pe = theta.out.df[,1:3]
  theta.dim = dim(theta.out.df)[2]
  theta.pe$SupDem_trim = apply(theta.out.df[,4:theta.dim], 1, mean)
  
  first.yr = data.frame(Country=levels(df2$Country),
                        First_yr = as.vector(by(df2, df2$Country, function(x) min(as.numeric(x$Year))+1987)))
  
  theta.pe = merge(theta.pe, first.yr, by="Country", all.x=TRUE)
  cnts = theta.pe[theta.pe$Year==2008, "Country"]
  frst.yr = theta.pe[theta.pe$Year==2008, "First_yr"]
  for(i in 1:length(cnts)) {
    theta.pe[theta.pe$Country==cnts[i] & theta.pe$Year<frst.yr[i], "SupDem_trim"] = NA
  }
  path = paste("output/niter/stan_est_sup_dem_m5_run", as.character(n.iter), ".csv", sep="")
  write.csv(theta.pe, path , row.names=FALSE)
  
  end_time <- Sys.time()
  times[t] = end_time - start_time
  t = t+1
}
save(times, itergrid, file = "output/comp_times.RData")
```



```{r convergence-niter}
df_iter = read.csv("output/niter/stan_est_sup_dem_m5_run10.csv")
names(df_iter)[names(df_iter) == 'SupDem_trim'] <- 'theta10'

for(n.iter in itergrid[-1]){#without first iteration
  temp_str = paste("output/niter/stan_est_sup_dem_m5_run", as.character(n.iter), ".csv", sep="")
  df_temp = read.csv(temp_str)
  temp_str = paste("theta", as.character(n.iter), sep="")
  df_iter[temp_str] = df_temp$SupDem_trim

  
  
}

df_iter$First_yr = NULL
df_iter$ISO_code = NULL



cnt.obs.years = cnt.obs.years[cnt.obs.years > 1]
bottom3_data_countries = names(sort(cnt.obs.years)[1:3])
top3_data_countries = names(sort(cnt.obs.years)[(length(cnt.obs.years)-2):(length(cnt.obs.years))])
# select countries
Austria = as.numeric(df_iter[df_iter$Country=="Austria" & df_iter$Year==2008, ][, c(3:ncol(df_iter))])
Azerbaijan = as.numeric(df_iter[df_iter$Country=="Azerbaijan" & df_iter$Year==2008, ][, c(3:ncol(df_iter))])
Bahrain =  as.numeric(df_iter[df_iter$Country=="Bahrain" & df_iter$Year==2008, ][, c(3:ncol(df_iter))])
Uruguay = as.numeric(df_iter[df_iter$Country=="Uruguay" & df_iter$Year==2008, ][, c(3:ncol(df_iter))])
Venezuela = as.numeric(df_iter[df_iter$Country=="Venezuela" & df_iter$Year==2008, ][, c(3:ncol(df_iter))])
Argentina = as.numeric(df_iter[df_iter$Country=="Argentina" & df_iter$Year==2008, ][, c(3:ncol(df_iter))])


df = data.frame(itergrid, Austria, Azerbaijan, Bahrain, Uruguay, Venezuela, Argentina)
#rownames(df) = itergrid






```

```{r}



library("tidyverse")
df_plot <- df %>%
  #select(itergrid, Austria, Azerbaijan, Bahrain, Uruguay, Venezuela, Argentina) %>%
  gather(key = "Country", value = "theta", -itergrid)
head(df_plot)


# Visualization
# Reorder following the value of another column:
df_plot %>%
  mutate(Country = fct_relevel(Country,"Austria", "Azerbaijan", "Bahrain", "Uruguay", "Venezuela", "Argentina")) %>%
  ggplot(aes(x = itergrid, y = theta, colour = Country))  + geom_line()  + geom_point() + xlab("Iteration") + ylab(TeX("$\\hat{\\theta}_{2008}$")) + scale_colour_brewer(palette="RdBu")

```


```{r sim-warmup, eval=False}
# CHANGE NITER TO 150!!!!
warm_grid = seq(0, 9, 1)

# number of repititions for distr
rep_grid = seq(1,3,1)


n.chn = 4
n.thin = 1
n.iter = 150
for(warm in warm_grid){
  n.warm = floor(n.iter* warm/10) # throw away warm_grid * 10 percent
  for (rep in rep_grid){

  
    # best model from PA article (model 5)
    stan.mod.5 = stan(file='model5.stan', data=dat.2, pars=pars.5, 
                       iter=n.iter, warmup=n.warm, chains=n.chn, thin=n.thin, 
                       control=list(adapt_delta=0.99, stepsize=0.02, max_treedepth=11), seed=n.warm*rep)
    
    
    #### Extract theta estimates
    
    theta.out = rstan::extract(stan.mod.5, pars = c("theta"))[[1]]
    theta.std = (theta.out - mean(as.vector(theta.out))) / sd(as.vector(theta.out)) # standardize
    theta.out.t = apply( theta.std, 1, function(x) t(x) )
    theta.out.df = data.frame(Country=rep(cnt.names, length.out=n.cntrys*30), 
                              ISO_code=rep(cnt.code, length.out=n.cntrys*30),
                              Year=rep(1988:2017, each=n.cntrys), theta.out.t)
    theta.pe = theta.out.df[,1:3]
    theta.dim = dim(theta.out.df)[2]
    theta.pe$SupDem_trim = apply(theta.out.df[,4:theta.dim], 1, mean)
    
    first.yr = data.frame(Country=levels(df2$Country),
                          First_yr = as.vector(by(df2, df2$Country, function(x) min(as.numeric(x$Year))+1987)))
    
    theta.pe = merge(theta.pe, first.yr, by="Country", all.x=TRUE)
    cnts = theta.pe[theta.pe$Year==2008, "Country"]
    frst.yr = theta.pe[theta.pe$Year==2008, "First_yr"]
    for(i in 1:length(cnts)) {
      theta.pe[theta.pe$Country==cnts[i] & theta.pe$Year<frst.yr[i], "SupDem_trim"] = NA
    }
    path = paste("output/warm/stan_est_sup_dem_m5_warm", as.character(n.warm), "_rep", as.character(rep), ".csv", sep="")
    write.csv(theta.pe, path , row.names=FALSE)
    

  }
}



```


```{r data-convergence-warmup}
warm_grid = seq(0, 9, 1)

# number of repititions for distr
rep_grid = seq(1,3,1)

n.iter = 150
df_warm= read.csv("output/warm/stan_est_sup_dem_m5_warm0_rep1.csv")
names(df_warm)[names(df_warm) == 'SupDem_trim'] <- 'theta0'
theta0 = c(df_warm[df_warm$Year == 2008 & df_warm$Country == "United States of America","theta0"], NA, NA)
df_warm <- data.frame(theta0)

for(warm in warm_grid){
  n.warm = floor(n.iter* warm/10) # throw away warm_grid * 10 percent
  theta_str = paste(as.character(n.warm), sep="")
  df_warm[theta_str] = c(NA, NA, NA)

  for (rep in rep_grid){
    
    path_str = paste("output/warm/stan_est_sup_dem_m5_warm", as.character(n.warm), "_rep", as.character(rep), ".csv", sep="")
    df_temp = read.csv(path_str)
    df_warm[theta_str][rep, ] = df_temp[df_temp$Year == 2008 & df_temp$Country == "United States of America",'SupDem_trim']
    
    
    
    
  }   
}
df_warm$theta0 = NULL
```

```{r}
sdf = stack(df_warm)
sdf$Warmup <- as.factor(sdf$ind) # for different color tones
sdf$ind = NULL

grids(axis = c("xy", "x", "y"), color = "grey92", size = NULL, linetype = NULL)

#sdf["theta"] = sdf$ind
ggplot(sdf, aes(x=Warmup, y=values, fill=Warmup)) + 
  geom_dotplot(binaxis='y', stackdir='center') + scale_x_discrete(labels= floor(n.iter* warm_grid/10)) + xlab("Warmup") + ylab(TeX("$\\hat{\\theta}_{USA, 2008}$")) + scale_fill_brewer(palette="Blues") + grids(linetype = "dashed") + theme(legend.position="none")


```





```{r sim-nchains, eval=False}
chain_grid = seq(1, 8, 1)

# number of repititions for distr
rep_grid = seq(1,3,1)


n.chn = 4
n.thin = 1
n.iter = 150
n.warm = floor(n.iter/2)
for(n.chain in chain_grid){
  for (rep in rep_grid){
  
  
    # best model from PA article (model 5)
    stan.mod.5 = stan(file='model5.stan', data=dat.2, pars=pars.5, 
                       iter=n.iter, warmup=n.warm, chains=n.chn, thin=n.thin, 
                       control=list(adapt_delta=0.99, stepsize=0.02, max_treedepth=11), seed=n.chain*rep)
    
    
    #### Extract theta estimates
    
    theta.out = rstan::extract(stan.mod.5, pars = c("theta"))[[1]]
    theta.std = (theta.out - mean(as.vector(theta.out))) / sd(as.vector(theta.out)) # standardize
    theta.out.t = apply( theta.std, 1, function(x) t(x) )
    theta.out.df = data.frame(Country=rep(cnt.names, length.out=n.cntrys*30), 
                              ISO_code=rep(cnt.code, length.out=n.cntrys*30),
                              Year=rep(1988:2017, each=n.cntrys), theta.out.t)
    theta.pe = theta.out.df[,1:3]
    theta.dim = dim(theta.out.df)[2]
    theta.pe$SupDem_trim = apply(theta.out.df[,4:theta.dim], 1, mean)
    
    first.yr = data.frame(Country=levels(df2$Country),
                          First_yr = as.vector(by(df2, df2$Country, function(x) min(as.numeric(x$Year))+1987)))
    
    theta.pe = merge(theta.pe, first.yr, by="Country", all.x=TRUE)
    cnts = theta.pe[theta.pe$Year==2008, "Country"]
    frst.yr = theta.pe[theta.pe$Year==2008, "First_yr"]
    for(i in 1:length(cnts)) {
      theta.pe[theta.pe$Country==cnts[i] & theta.pe$Year<frst.yr[i], "SupDem_trim"] = NA
    }
    path = paste("output/chain/stan_est_sup_dem_m5_chain", as.character(n.chain), "_rep", as.character(rep), ".csv", sep="")
    write.csv(theta.pe, path , row.names=FALSE)
    

  }
}

```

```{r data-convergence-warmup}
chain_grid = seq(1, 8, 1)

# number of repititions for distr
rep_grid = seq(1,3,1)

n.iter = 150

df_chain= read.csv("output/chain/stan_est_sup_dem_m5_chain1_rep1.csv")
names(df_chain)[names(df_chain) == 'SupDem_trim'] <- 'theta1'
theta1 = c(df_chain[df_chain$Year == 2008 & df_chain$Country == "United States of America","theta1"], NA, NA)
df_chain <- data.frame(theta1)

for(chain in chain_grid){
  theta_str = paste("theta", as.character(chain), sep="")
  df_chain[theta_str] = c(NA, NA, NA)

  for (rep in rep_grid){
    
    path_str = paste("output/chain/stan_est_sup_dem_m5_chain", as.character(chain), "_rep", as.character(rep), ".csv", sep="")
    df_temp = read.csv(path_str)
    df_chain[theta_str][rep, ] = df_temp[df_temp$Year == 2008 & df_temp$Country == "United States of America",'SupDem_trim']
    
    
    
    
  }   
}

```
